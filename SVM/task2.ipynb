{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "# import tensorflow as tf \n",
    "import sklearn as sk \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew \n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 'Soil_Type_2702', 'Soil_Type_2703', 'Soil_Type_2704', 'Soil_Type_2705', 'Soil_Type_2706', 'Soil_Type_2717', 'Soil_Type_4703', 'Soil_Type_4704', 'Soil_Type_4758', 'Soil_Type_5101', 'Soil_Type_6101', 'Soil_Type_6102', 'Soil_Type_7102', 'Soil_Type_7756', 'Soil_Type_7757']\n"
     ]
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('train.csv')\n",
    "\n",
    "X = dataset_train.iloc[:, 1:12]\n",
    "n = X.shape[0]\n",
    "# print(X.head(3))\n",
    "Y = dataset_train.iloc[:, 12]\n",
    "# test train split\n",
    "# # =============================================================================\n",
    "dataset_test = pd.read_csv('test.csv')\n",
    "Xtest = dataset_test.iloc[:, 1:12]\n",
    "\n",
    "X_all = pd.concat([X,Xtest], axis=0)\n",
    "\n",
    "X_all['Soil_Type'] = X_all['Soil_Type'].astype('category') \n",
    "X_all = pd.get_dummies(X_all)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(np.array(X.iloc[:,:9]))\n",
    "X_std = scaler.transform(np.array(X.iloc[:,:9]))\n",
    "X_std = pd.DataFrame(X_std)\n",
    "\n",
    "X_std_full = pd.concat([X_std,X_all.iloc[:n,10::]],axis = 1)\n",
    "print(list(X_std_full))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_std_full, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_std_full, Y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=6.4, cache_size=200, class_weight=None, coef0=0.7,\n",
      "  decision_function_shape='ovr', degree=1.5, gamma=0.9, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV # Search over specified parameter values for an estimator.\n",
    "from sklearn.model_selection import RandomizedSearchCV # Search over specified parameter values for an estimator.\n",
    "from sklearn.model_selection import ShuffleSplit # Random permutation cross-validator\n",
    "from sklearn.svm import SVC\n",
    "from AUC import AUC\n",
    "classifier = SVC(kernel = 'rbf', random_state=42)\n",
    "cv_sets = ShuffleSplit(random_state = 4) # shuffling our data for cross-validation\n",
    "parameters = {'gamma':(np.arange(1,40)/20).tolist(),\n",
    "\t\t\t  'degree':(np.arange(1,40)/2).tolist(),\n",
    "\t\t\t  'C': (np.arange(1,40)/5).tolist(),\n",
    "\t\t\t  'coef0' :(np.arange(1,40)/20).tolist()}\n",
    "scorer = make_scorer(AUC,greater_is_better =True)\n",
    "n_iter_search = 10\n",
    "grid_obj = RandomizedSearchCV(classifier, \n",
    "                              parameters, \n",
    "                              n_iter = n_iter_search, \n",
    "                              scoring = scorer, \n",
    "                              cv = cv_sets,\n",
    "                              random_state= 99)\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "rf_opt = grid_fit.best_estimator_\n",
    "print(grid_fit.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  1.518814 -0.393620  0.362423  0.222200  0.803259  1.637816  1.153551   \n",
      "1  0.575510 -1.377395  1.253873  0.166062  0.752148  0.311122 -0.325161   \n",
      "2 -1.785298  1.286224  0.139560 -1.265448 -0.866373 -0.565211 -1.138453   \n",
      "\n",
      "          7         8         9       ...        Soil_Type_2717  \\\n",
      "0  0.190339 -1.030104  3.421162       ...                     0   \n",
      "1 -2.186893 -1.068270 -0.001647       ...                     0   \n",
      "2  0.010246  1.107186 -0.589732       ...                     0   \n",
      "\n",
      "   Soil_Type_4703  Soil_Type_4704  Soil_Type_4758  Soil_Type_5101  \\\n",
      "0               0               0               0               0   \n",
      "1               1               0               0               0   \n",
      "2               0               0               0               0   \n",
      "\n",
      "   Soil_Type_6101  Soil_Type_6102  Soil_Type_7102  Soil_Type_7756  \\\n",
      "0               0               0               0               0   \n",
      "1               0               0               0               0   \n",
      "2               0               1               0               0   \n",
      "\n",
      "   Soil_Type_7757  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "\n",
      "[3 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv('test.csv')\n",
    "\n",
    "Xtest = dataset_test.iloc[:, 1:12]\n",
    "# print(Xtest.head(3))\n",
    "Xtest['Soil_Type'] = Xtest['Soil_Type'].astype('category') \n",
    "\n",
    "scaler = StandardScaler().fit(np.array(X.iloc[:,[0,1,2,3,4,5,6,7,8,9]]))\n",
    "Xtest_std = scaler.transform(np.array(Xtest.iloc[:,[0,1,2,3,4,5,6,7,8,9]]))\n",
    "Xtest_std = pd.DataFrame(Xtest_std)\n",
    "Xtest_std_full = pd.concat([Xtest_std,X_all.iloc[n::,10::]],axis = 1)\n",
    "\n",
    "print(Xtest_std_full.head(3))\n",
    "\n",
    "\n",
    "#ids = dataset_test['ID']\n",
    "#predictions = svclass(X_std_full,Y,Xtest_std_full)\n",
    "\n",
    "# output = pd.DataFrame({ 'ID' : ids, 'From_Cache_la_Poudre': predictions })\n",
    "# output.to_csv('svm_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
