{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muzhou Liu muzhouliu@wustl.edu 465729\n",
    "\n",
    "Yidi Zhang yidi.zhang@wustl.edu 465621\n",
    "\n",
    "Ria Das  ria.das@wustl.edu 459319\n",
    "\n",
    "Selamawit Tegegn sntegegn@wustl.edu 451841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "# import tensorflow as tf \n",
    "import sklearn as sk \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#from scipy import stats\n",
    "#from scipy.stats import norm, skew \n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt  # Matlab-style plotting\n",
    "#import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Elevation          ...           Soil_Type  From_Cache_la_Poudre\n",
      "0   452309010       2468          ...                2703                     0\n",
      "1   754045784       2052          ...                2717                     1\n",
      "2  1347023875       2570          ...                2705                     0\n",
      "\n",
      "[3 rows x 13 columns]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 'Soil_Type_2702', 'Soil_Type_2703', 'Soil_Type_2704', 'Soil_Type_2705', 'Soil_Type_2706', 'Soil_Type_2717', 'Soil_Type_4703', 'Soil_Type_4704', 'Soil_Type_4758', 'Soil_Type_5101', 'Soil_Type_6101', 'Soil_Type_6102', 'Soil_Type_7102', 'Soil_Type_7756', 'Soil_Type_7757']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset_train = pd.read_csv('../input/train.csv')\n",
    "print(dataset_train.head(3))\n",
    "X = dataset_train.iloc[:, 1:12]\n",
    "n = X.shape[0]\n",
    "# print(X.head(3))\n",
    "Y = dataset_train.iloc[:, 12]\n",
    "# test train split\n",
    "# # =============================================================================\n",
    "dataset_test = pd.read_csv('../input/test.csv')\n",
    "Xtest = dataset_test.iloc[:, 1:12]\n",
    "\n",
    "X_all = pd.concat([X,Xtest], axis=0)\n",
    "\n",
    "X_all['Soil_Type'] = X_all['Soil_Type'].astype('category') \n",
    "X_all = pd.get_dummies(X_all)\n",
    "\n",
    "\n",
    "\n",
    "scaler = StandardScaler().fit(np.array(X.iloc[:,[0,1,2,3,4,5,6,7,8,9]]))\n",
    "X_std = scaler.transform(np.array(X.iloc[:,[0,1,2,3,4,5,6,7,8,9]]))\n",
    "X_std = pd.DataFrame(X_std)\n",
    "\n",
    "X_std_full = pd.concat([X_std,X_all.iloc[:n,10::]],axis = 1)\n",
    "print(list(X_std_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessClassifier \n",
    "from sklearn.gaussian_process.kernels import RBF \n",
    "\n",
    "def sklearn_gpc(xtr, ytr, xte):\n",
    "\tkernel = 1.0*RBF(1.0)\n",
    "\tgpc = GaussianProcessClassifier(kernel= kernel, random_state =666, n_jobs =-1)\n",
    "\n",
    "\tgpc.fit(xtr, ytr)\n",
    "\n",
    "\tpredict = gpc.predict_proba(xte)[:,1]\n",
    "\t# predict = gpc.predict(xte)\n",
    "\n",
    "\treturn(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ID  Elevation          ...           Soil_Type  From_Cache_la_Poudre\n",
      "0   452309010       2468          ...                2703                     0\n",
      "1   754045784       2052          ...                2717                     1\n",
      "2  1347023875       2570          ...                2705                     0\n",
      "\n",
      "[3 rows x 13 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset_test = pd.read_csv('../input/test.csv')\n",
    "print(dataset_train.head(3))\n",
    "Xtest = dataset_test.iloc[:, 1:12]\n",
    "# print(Xtest.head(3))\n",
    "Xtest['Soil_Type'] = Xtest['Soil_Type'].astype('category') \n",
    "\n",
    "scaler = StandardScaler().fit(np.array(X.iloc[:,[0,1,2,3,4,5,6,7,8,9]]))\n",
    "Xtest_std = scaler.transform(np.array(Xtest.iloc[:,[0,1,2,3,4,5,6,7,8,9]]))\n",
    "Xtest_std = pd.DataFrame(Xtest_std)\n",
    "Xtest_std_full = pd.concat([Xtest_std,X_all.iloc[n::,10::]],axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "ids = dataset_test['ID']\n",
    "predictions = sklearn_gpc(X_std_full,Y,Xtest_std_full)\n",
    "\n",
    "output = pd.DataFrame({ 'ID' : ids, 'From_Cache_la_Poudre': predictions })\n",
    "output.to_csv('svm_submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
